##Our working directory
setwd("D:/Research/MHP_Documents/Analysis with R")
getwd()

##Required libraries
library(readxl)
library(ggplot2)
library(ggradar)
library(caret)
library(tidyverse)
library(pROC)
library(rpart)
library(gridExtra)

##Upload the data file
MHP<-read_excel("df_MHP.AHC.xlsx")
head(MHP)

#Anxiety
df_MHP<-MHP[c(1,3:5,7:12)]
df_MHP$D<-as.factor(df_MHP$D)
df_MHP<-df_MHP|>
  mutate(D=factor(D,labels=c("No","Yes")))

#Data split
indexes<-createDataPartition(df_MHP$D,p=0.9,list=FALSE)
train<-df_MHP[indexes,]
test<-df_MHP[-indexes,]

#Fitting xgboost classification model with xgbTree method
set.seed(1)
system.time(xgbTree<-train(D~.,data=train,method="xgbTree",
                           trControl=trainControl(method="cv",number=10,
                                                  classProbs = TRUE, summaryFunction = twoClassSummary),
                           metric="ROC"))
xgbTree
xgbTree$results%>%arrange(desc(ROC))%>%head(1)

##Feature importance
varImp(xgbTree)

#Evaluation performance of the model
confusionMatrix(predict(xgbTree,test),test$D,positive="Yes")

#Precision & F1 score
cm<-matrix(c(9,11,3,101),nrow=2)
colnames(cm)<-c("No","Yes")
rownames(cm)<-c("No","Yes")
confusionMatrix(cm)$byClass[["Precision"]]


#ROC calculation
Roc.xgb<-roc(response=test$D,
         predictor=predict(xgbTree,newdata=test,type="prob")$Yes)
plot(Roc.xgb,legacy.axes=TRUE)
auc(Roc.xgb)

##Depression
df_MHP2<-MHP[c(1:11,13)]
df_MHP2$E<-as.factor(df_MHP2$E)
df_MHP2<-df_MHP2|>
  mutate(`E`=factor(`E`,labels=c("No","Yes")))

#Data split
indexes<-createDataPartition(df_MHP2$E,p=0.9,list=FALSE)
train2<-df_MHP2[indexes,]
test2<-df_MHP2[-indexes,]

#Fitting xgboost classification model with xgbTree method
set.seed(1)
system.time(xgbTree2<-train(`E`~.,data=train2,method="xgbTree",
                           trControl=trainControl(method="cv",number=5,
                                                  classProbs = TRUE, summaryFunction = twoClassSummary),
                           metric="ROC"))
xgbTree2
xgbTree2$results%>%arrange(desc(ROC))%>%head(1)

##Feature importance
varImp(xgbTree2)

#Evaluation performance of the model
confusionMatrix(predict(xgbTree2,test2),test2$E,positive="Yes")

#Precision & F1 score
cm<-matrix(c(7,12,3,102),nrow=2)
colnames(cm)<-c("No","Yes")
rownames(cm)<-c("No","Yes")
confusionMatrix(cm)$byClass[["Precision"]]

#ROC calculation
Roc.xgb2<-roc(response=test2$E,
         predictor=predict(xgbTree2,newdata=test2,type="prob")$Yes)
plot(Roc.xgb2,legacy.axes=TRUE)
auc(Roc.xgb2)

##Insomnia
df_MHP3<-MHP[c(1:11,14)]
df_MHP3$F<-as.factor(df_MHP3$F)
df_MHP3<-df_MHP3|>
  mutate(`F`=factor(`F`,labels=c("No","Yes")))

#Data split
indexes<-createDataPartition(df_MHP3$F,p=0.9,list=FALSE)
train3<-df_MHP3[indexes,]
test3<-df_MHP3[-indexes,]

#Fitting xgboost classification model with xgbTree method
set.seed(1)
system.time(xgbTree3<-train(`F`~.,data=train3,method="xgbTree",
                            trControl=trainControl(method="cv",number=10,
                                                   classProbs = TRUE, summaryFunction = twoClassSummary),
                            metric="ROC"))
xgbTree3
xgbTree3$results%>%arrange(desc(ROC))%>%head(1)

##Feature importance
varImp(xgbTree3)

#Evaluation performance of the model
confusionMatrix(predict(xgbTree3,test3),test3$F,positive="Yes")

#Precision & F1 score
cm<-matrix(c(17,12,9,86),nrow=2)
colnames(cm)<-c("No","Yes")
rownames(cm)<-c("No","Yes")
confusionMatrix(cm)$byClass[["Precision"]]

#ROC calculation
Roc.xgb3<-roc(response=test3$F,
          predictor=predict(xgbTree3,newdata=test3,type="prob")$Yes)
plot(Roc.xgb3,legacy.axes=TRUE)
auc(Roc.xgb3)


